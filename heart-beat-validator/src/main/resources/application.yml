spring:
  kafka:
    bootstrap-servers:
      - localhost:9092
    properties:
      # using a schema registry to fetch the Avro schemas
      # see https://docs.confluent.io/current/schema-registry/index.html
      schema.registry.url: http://localhost:8081
    streams:
      application-id: heart-beat-validator
      replication-factor: 1
      # streams properties can be found in org.apache.kafka.clients.streams.StreamsConfig
      properties:
        default.key.serde: org.apache.kafka.common.serialization.Serdes$LongSerde
        # since my HeartBeat Avro schema is specific (I'm using a specific timestamp), I need to use SpecificAvroSerde, not GenericAvroSerde
        default.value.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
  jackson:
    # ensure the input/output in epoch milli are correctly read/written by Jackson
    deserialization:
      READ_DATE_TIMESTAMPS_AS_NANOSECONDS: false
    serialization:
      WRITE_DATE_TIMESTAMPS_AS_NANOSECONDS: false
  main:
    banner-mode: OFF
logging:
  level:
    # to have the topology of the stream described in the log at the start of the app
    org.springframework.kafka.config.StreamsBuilderFactoryBean: DEBUG
server:
  port: 8280

# application specific
topics:
  from: heart-beats
  to:
    valid:
      name: heart-beats-valid
      partitions: 1
      replicas: 1
    invalid:
      name: heart-beats-invalid
      partitions: 1
      replicas: 1
